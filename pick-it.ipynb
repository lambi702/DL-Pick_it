{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data\\original\\dataset_3d_vnir_xrt.pkl\")\n",
    "\n",
    "print(\"Nb samples: \",len(df))\n",
    "print(\"Nb chanels in data_cube: \",len(df[\"data_cube\"][0]))\n",
    "print(\"\")\n",
    "print(\"Shape of 2 random samples: \")\n",
    "s1, s2 = random.choice(range(len(df))), random.choice(range(len(df)))\n",
    "print(\"     sample 1: \",df[\"data_cube\"][s1].shape)\n",
    "print(\"     sample 2: \",df[\"data_cube\"][s2].shape)\n",
    "print(\"Nb categories: \",len(df[\"class\"].unique()))\n",
    "\n",
    "plt.subplots(1,2,figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(df[\"data_cube\"][s1][0])\n",
    "plt.title(\"Sample 1: layer 0\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(df[\"data_cube\"][s2][0])\n",
    "plt.title(\"Sample 2: layer 0\")\n",
    "\n",
    "pi_data_dict = {0: \"3D\",\n",
    "                1: \"VNIR 1\",\n",
    "                2: \"VNIR 2\",\n",
    "                3: \"VNIR 3\",\n",
    "                4: \"VNIR 4\",\n",
    "                5: \"VNIR 5\",\n",
    "                6: \"VNIR 6\",\n",
    "                7: \"VNIR 7\",\n",
    "                8: \"VNIR 8\",\n",
    "                9: \"XRT 1\",\n",
    "                10: \"XRT 2\"}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of a dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PickItDataset(Dataset):    \n",
    "    def __init__(self, pickle_path, transform=None,train = True, seed = 42):\n",
    "        data = pd.read_pickle(pickle_path)\n",
    "        data[\"cube\"] = data[\"data_cube\"].apply(lambda x: x.astype(np.float32))\n",
    "        cube = data[\"cube\"]\n",
    "        mask = data[\"masks\"]\n",
    "        random.seed(seed)\n",
    "        test_indices = random.sample(range(0, len(data)), int(len(data) * 0.2))\n",
    "        if train:\n",
    "            cube = cube.drop(test_indices)\n",
    "            mask = mask.drop(test_indices)\n",
    "            data = data.drop(test_indices)\n",
    "        else:\n",
    "            cube = cube.iloc[test_indices]\n",
    "            mask = mask.iloc[test_indices]\n",
    "            data = data.iloc[test_indices]\n",
    "        self.data = cube\n",
    "        self.masks = mask\n",
    "        self.labels = data[\"class\"]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            index = index.tolist()\n",
    "\n",
    "        data = torch.from_numpy(self.data[idx])\n",
    "        mask = torch.tensor(self.masks[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sample = {\"data\": data,\"mask\":mask, \"label\": label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    def __init__(self, scale):\n",
    "        self.scale = scale\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        data, mask ,label = sample[\"data\"], sample[\"mask\"],sample[\"label\"]\n",
    "        data = transforms.Resize(self.scale)(data)\n",
    "        mask = transforms.Resize(self.scale)(mask.unsqueeze(0)).squeeze(0)\n",
    "        return {\"data\": data,\"mask\":mask ,\"label\": label}\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        data, mask, label = sample[\"data\"], sample[\"mask\"], sample[\"label\"]\n",
    "        if random.random() < self.p:\n",
    "            data = transforms.RandomHorizontalFlip(p=1)(data)\n",
    "            mask = transforms.RandomHorizontalFlip(p=1)(mask)\n",
    "        return {\"data\": data,\"mask\":mask ,\"label\": label}\n",
    "\n",
    "class RandomVerticalFlip(object):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        data, mask ,label = sample[\"data\"], sample[\"mask\"],sample[\"label\"]\n",
    "        if random.random() < self.p:\n",
    "            data = transforms.RandomVerticalFlip(p=1)(data)\n",
    "            mask = transforms.RandomVerticalFlip(p=1)(mask)\n",
    "        return {\"data\": data,\"mask\":mask ,\"label\": label}\n",
    "\n",
    "class Normalize(object):\n",
    "    def __call__(self, sample):\n",
    "        data, mask, label = sample[\"data\"], sample[\"mask\"], sample[\"label\"]\n",
    "        mean = torch.mean(data)\n",
    "        std = torch.std(data)\n",
    "        data = transforms.Normalize(mean,std)(data)\n",
    "        return {\"data\": data,\"mask\":mask ,\"label\": label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(sample, layer):\n",
    "    plt.imshow(sample[\"data\"][layer])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loadind the dataset, applying the transforms and creating the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"data\\original\\dataset_3d_vnir_xrt.pkl\"\n",
    "new_scale = (256, 256)\n",
    "p_flip = 0.5\n",
    "batch_size = 4\n",
    "num_workers = 0\n",
    "seed = 42\n",
    "\n",
    "tr_train = transforms.Compose([Rescale(new_scale),RandomHorizontalFlip(p_flip),RandomVerticalFlip(p_flip),Normalize()])\n",
    "tr_test = transforms.Compose([Rescale(new_scale),Normalize()])\n",
    "\n",
    "trainset = PickItDataset(pickle_path, transform=tr_train,train = True, seed = seed)\n",
    "testset = PickItDataset(pickle_path, transform=tr_test,train = False, seed = seed)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

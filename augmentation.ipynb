{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import pickle \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 72 and the array at index 1 has size 66",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m keys:\n\u001b[0;32m     16\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(indexes[i]),\u001b[39m2\u001b[39m):\n\u001b[0;32m     17\u001b[0m         \u001b[39m# concatenate two images\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m         new_dataset[\u001b[39m\"\u001b[39m\u001b[39mdata_cube\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mconcatenate((dataset[\u001b[39m\"\u001b[39;49m\u001b[39mdata_cube\u001b[39;49m\u001b[39m\"\u001b[39;49m][indexes[i][j]],dataset[\u001b[39m\"\u001b[39;49m\u001b[39mdata_cube\u001b[39;49m\u001b[39m\"\u001b[39;49m][indexes[i][j\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m]]),axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))\n\u001b[0;32m     19\u001b[0m         new_dataset[\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m i\n\u001b[0;32m     20\u001b[0m         new_dataset[\u001b[39m\"\u001b[39m\u001b[39mmasks\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mconcatenate((dataset[\u001b[39m\"\u001b[39m\u001b[39mmasks\u001b[39m\u001b[39m\"\u001b[39m][indexes[i][j]],dataset[\u001b[39m\"\u001b[39m\u001b[39mmasks\u001b[39m\u001b[39m\"\u001b[39m][indexes[i][j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]]),axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 72 and the array at index 1 has size 66"
     ]
    }
   ],
   "source": [
    "pickle_path = \"datasets\\pick-it\\dataset_3d_vnir_xrt.pkl\"\n",
    "#pickle_path = \"/datasets/pick-it/dataset_3d_vnir_xrt.pkl\"\n",
    "pkl = open(pickle_path, 'rb')\n",
    "dataset = pickle.load(pkl)\n",
    "# group by class\n",
    "grouped = dataset.groupby('class')\n",
    "keys = list(grouped.groups.keys())\n",
    "indexes ={k:[] for k in keys}\n",
    "for i in keys:\n",
    "    # suffle indexes\n",
    "    indexes[i] = list(grouped.groups[i])\n",
    "    random.shuffle(indexes[i])\n",
    "new_dataset = {\"data_cube\":[],\"class\":[],\"masks\":[]}\n",
    "\n",
    "for i in keys:\n",
    "    for j in range(0,len(indexes[i]),2):\n",
    "        # concatenate two images\n",
    "        new_dataset[\"data_cube\"].append(np.concatenate((dataset[\"data_cube\"][indexes[i][j]],dataset[\"data_cube\"][indexes[i][j+1]]),axis=0))\n",
    "        new_dataset[\"class\"] = i\n",
    "        new_dataset[\"masks\"].append(np.concatenate((dataset[\"masks\"][indexes[i][j]],dataset[\"masks\"][indexes[i][j+1]]),axis=0))\n",
    "new_dataset = pd.DataFrame(new_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

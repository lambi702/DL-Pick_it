{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, input_chan, output_chan, downsample = None, stride= 1):\n",
    "        super(Block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(input_chan, output_chan, kernel_size= 1, stride=1, padding = 0)\n",
    "        self.batch_n1 = nn.BatchNorm2d(output_chan)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(input_chan, output_chan, kernel_size= 1, stride=stride, padding = 1)\n",
    "        self.batch_n2 = nn.BatchNorm2d(output_chan)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(output_chan, output_chan*self.expansion, kernel_size= 1, stride=1, padding = 0)\n",
    "        self.batch_n3 = nn.BatchNorm2d(output_chan*self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self,x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_n1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_n2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_n3(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "\n",
    "        x= x + identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, Block, layers, channels, num_output):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.input_chan = 64\n",
    "        self.conv1 = nn.Conv2d(channels, 64, kernel_size = 7, stride=2, padding = 3)\n",
    "        self.batch_n1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "\n",
    "        #Resnet layers  \n",
    "\n",
    "        self.layer1 = self._make_layer(Block,layers[0], output_chan = 64, stride = 1)\n",
    "        self.layer2 = self._make_layer(Block,layers[1], output_chan = 128, stride = 2)\n",
    "        self.layer3 = self._make_layer(Block,layers[2], output_chan = 256, stride = 2)\n",
    "        self.layer4 = self._make_layer(Block,layers[3], output_chan = 512, stride = 2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*4, num_output)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_n1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x= self.layer1(x)\n",
    "        x= self.layer2(x)\n",
    "        x= self.layer3(x)\n",
    "        x= self.layer4(x)\n",
    "\n",
    "        x= self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        x= self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, Block, num_residual_blocks, output_chan, stride):\n",
    "        downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.input_chan != output_chan*4:\n",
    "            downsample = nn.Sequential(nn.Conv2d(self.input_chan, output_chan*4, kernel_size=1, stride = stride),\n",
    "                                        nn.BatchNorm2d(output_chan*4))\n",
    "            \n",
    "        layers.append(Block(self.input_chan, output_chan, downsample, stride))\n",
    "        self.input_chan = output_chan*4\n",
    "\n",
    "        for i in range(num_residual_blocks-1):\n",
    "            layers.append(Block(self.input_chan, output_chan))\n",
    "\n",
    "        return(nn.Sequential(*layers))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
